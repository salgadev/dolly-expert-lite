{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqysgnKYgFRe",
        "outputId": "1736af0e-2c74-47f7-e131-8bae2f46967b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.29.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.19.0)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.6.1)\n",
            "Requirement already satisfied: Xformers in /usr/local/lib/python3.10/dist-packages (0.0.20)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.0.191)\n",
            "Requirement already satisfied: InstructorEmbedding in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.10/dist-packages (0.3.26)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n",
            "Requirement already satisfied: pyre-extensions==0.0.29 in /usr/local/lib/python3.10/dist-packages (from Xformers) (0.0.29)\n",
            "Requirement already satisfied: typing-inspect in /usr/local/lib/python3.10/dist-packages (from pyre-extensions==0.0.29->Xformers) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pyre-extensions==0.0.29->Xformers) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (16.0.5)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.10)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.4)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.2)\n",
            "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.5.7)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.4)\n",
            "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.2.4)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.7)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.15.2+cu118)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.10.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (3.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.1.99)\n",
            "Requirement already satisfied: pandas>=1.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.5.3)\n",
            "Requirement already satisfied: hnswlib>=0.7 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.7.0)\n",
            "Requirement already satisfied: clickhouse-connect>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.6.1)\n",
            "Requirement already satisfied: duckdb>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.7.1)\n",
            "Requirement already satisfied: fastapi>=0.85.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.96.0)\n",
            "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.22.0)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.0.1)\n",
            "Requirement already satisfied: pulsar-client>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.2.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.15.0)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (7.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from clickhouse-connect>=0.5.7->chromadb) (2022.12.7)\n",
            "Requirement already satisfied: urllib3>=1.26 in /usr/local/lib/python3.10/dist-packages (from clickhouse-connect>=0.5.7->chromadb) (1.26.15)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from clickhouse-connect>=0.5.7->chromadb) (2022.7.1)\n",
            "Requirement already satisfied: zstandard in /usr/local/lib/python3.10/dist-packages (from clickhouse-connect>=0.5.7->chromadb) (0.21.0)\n",
            "Requirement already satisfied: lz4 in /usr/local/lib/python3.10/dist-packages (from clickhouse-connect>=0.5.7->chromadb) (4.3.2)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
            "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
            "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.85.1->chromadb) (0.27.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (23.3.3)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3->chromadb) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (8.1.3)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.5.0)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.0)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.17.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.19.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (11.0.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers) (8.4.0)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.28.0,>=0.27.0->fastapi>=0.85.1->chromadb) (3.6.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect->pyre-extensions==0.0.29->Xformers) (1.0.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->accelerate) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi>=0.85.1->chromadb) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers accelerate einops Xformers langchain InstructorEmbedding sentence-transformers chromadb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "\n",
        "!pip install unstructured pandoc"
      ],
      "metadata": {
        "id": "_JnTRRxOgJBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CLEAR CUDA\n",
        "import gc\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n"
      ],
      "metadata": {
        "id": "WBKifJx9slzS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_name = \"databricks/dolly-v2-3b\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, padding_side=\"left\")\n",
        "\n",
        "generate_text = pipeline(model=model_name, torch_dtype=torch.bfloat16,\n",
        "                         trust_remote_code=True, device_map=\"auto\", return_full_text=True)"
      ],
      "metadata": {
        "id": "jync0GxwMHev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "import torch\n",
        "\n",
        "hf_pipeline = HuggingFacePipeline(pipeline=generate_text)\n",
        "\n",
        "# template for an instrution with no input\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"instruction\"],\n",
        "    template=\"{instruction}\")\n",
        "\n",
        "llm_chain = LLMChain(llm=hf_pipeline, prompt=prompt)"
      ],
      "metadata": {
        "id": "Yfyc6poyqEO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hf_pipeline"
      ],
      "metadata": {
        "id": "Lyim-npjyrSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Check if input is checked somewhere, otherwise check something like this:\n",
        "\n",
        "# Your output sequence\n",
        "output_sequence = \"This is an example output sequence.\"\n",
        "\n",
        "# Tokenize the output sequence\n",
        "tokenized_output = tokenizer.encode(output_sequence, return_tensors=\"pt\")\n",
        "\n",
        "# Count the number of tokens in the tokenized sequence\n",
        "num_tokens = tokenized_output.shape[1]\n",
        "\n",
        "print(f\"Number of tokens in the output sequence: {num_tokens}\")"
      ],
      "metadata": {
        "id": "kKk0JeMxXJo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test LLM Chain"
      ],
      "metadata": {
        "id": "6xT4zJ7TgWcz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = 'Who was Dolly the sheep?'\n",
        "llm_chain.run(question)"
      ],
      "metadata": {
        "id": "W0dMXmJzgOT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = 'what are the colors of the rainbow?'\n",
        "llm_chain.run(question)"
      ],
      "metadata": {
        "id": "ldq-gA83uOY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare Documents\n"
      ],
      "metadata": {
        "id": "VWBP01QduLFa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nest_asyncio"
      ],
      "metadata": {
        "id": "S3tQjzWQMpME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fixes a bug with asyncio and jupyter\n",
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "06U43xzXMvvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders.sitemap import SitemapLoader\n"
      ],
      "metadata": {
        "id": "jfoG5BoFMtsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.document_loaders import DirectoryLoader"
      ],
      "metadata": {
        "id": "vsU1sHkfuML8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sitemap_loader = SitemapLoader(web_path=\"https://www.limestone.on.ca/sitemap.xml\")\n",
        "\n",
        "docs = sitemap_loader.load()"
      ],
      "metadata": {
        "id": "5DR5Xy2MM0YU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "texts = text_splitter.split_documents(docs)"
      ],
      "metadata": {
        "id": "4VPvW8LtNRIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(texts)"
      ],
      "metadata": {
        "id": "ppOdTyJW9rHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts[2]"
      ],
      "metadata": {
        "id": "X021P1rb9tQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download HuggingFace Embeddings\n",
        "Check [MTEB English Leaderboard](https://huggingface.co/spaces/mteb/leaderboard) to make sure you download embeddings with good performance"
      ],
      "metadata": {
        "id": "iECM1b-Gv4r1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose one of the top performers from the MTEB English Leaderboard\n",
        "\n",
        "from langchain.embeddings import HuggingFaceEmbeddings, SentenceTransformerEmbeddings\n",
        "\n",
        "# top #2 when task = Retrieval June 2023 for under ~500 MB\n",
        "model_name = \"intfloat/e5-base-v2\" \n",
        "\n",
        "hf = HuggingFaceEmbeddings(model_name=model_name)"
      ],
      "metadata": {
        "id": "xpHOw1w6vz5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make a Vector Database"
      ],
      "metadata": {
        "id": "_nobGwTHyPp7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Embed and store the texts\n",
        "# Supplying a persist_directory will store the embeddings on disk\n",
        "persist_directory = 'db'\n",
        "\n",
        "## Here is the nmew embeddings being used\n",
        "embedding = hf \n",
        "\n",
        "vectordb = Chroma.from_documents(documents=texts, \n",
        "                                 embedding=embedding,\n",
        "                                 persist_directory=persist_directory)"
      ],
      "metadata": {
        "id": "1JWklk3NyDwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# and a retriever"
      ],
      "metadata": {
        "id": "oUYiixFsyj36"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectordb.as_retriever(search_kwargs={'k':2})"
      ],
      "metadata": {
        "id": "4QhWuhHWyQ6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "X56saDf9-bG-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test the basic retriever"
      ],
      "metadata": {
        "id": "_2ozWd-Ezkpu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docs = retriever.get_relevant_documents(\"How much is tuition?\")"
      ],
      "metadata": {
        "id": "SS46HKb2zHBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs[0]"
      ],
      "metadata": {
        "id": "zukHNae1ywxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make a proper Question Retrieval chain"
      ],
      "metadata": {
        "id": "qClCY86Pz6QN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "from typing import Dict, Any\n",
        "\n",
        "class AnswerConversationBufferMemory(ConversationBufferMemory):\n",
        "    def save_context(self, inputs: Dict[str, Any], outputs: Dict[str, str]) -> None:\n",
        "        return super(AnswerConversationBufferMemory, self).save_context(inputs,{'response': outputs['result']})"
      ],
      "metadata": {
        "id": "egEcNF5gSh17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_chain_with_memory = RetrievalQA.from_chain_type(llm=hf_pipeline, \n",
        "                                                   chain_type=\"stuff\", \n",
        "                                                   retriever=retriever, \n",
        "                                                   return_source_documents=True,\n",
        "                                                   memory=AnswerConversationBufferMemory())"
      ],
      "metadata": {
        "id": "aBLpXIj2Qkxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# try to set the tone to \"as a human-like Student Advisor\"\n",
        "qa_chain_with_memory.combine_documents_chain.llm_chain.prompt.template = '''\n",
        "You are a prospective student advisor for a university. You are talkative and provide lots of specific details using the context given by the users question. \n",
        "If you don't know the answer, you truthfully say you don't know and don't try to make up an answer. You use the information contained in the \"Relevant Information\" section and You always answer with unbiased, ETHICAL and safe advise.\n",
        "\n",
        "Relevant Information:\n",
        "{history}\n",
        "\n",
        "Conversation:\n",
        "\n",
        "Question: {question}\n",
        "Helpful Answer:'''\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"history\", \"question\"], template=template)"
      ],
      "metadata": {
        "id": "JZHanH3uRLCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"How much is tuition in engineering?\"\n",
        "llm_response = qa_chain_with_memory(query)\n",
        "process_llm_response(llm_response)"
      ],
      "metadata": {
        "id": "LPrKeuC_RS-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"How much is tuition in med school?\"\n",
        "llm_response = qa_chain_with_memory(query)\n",
        "process_llm_response(llm_response)"
      ],
      "metadata": {
        "id": "ivGgtLvRTobQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"I am interested in both medicine and engineering, do you have a program that is a mix of the two?\"\n",
        "llm_response = qa_chain_with_memory(query)\n",
        "process_llm_response(llm_response)"
      ],
      "metadata": {
        "id": "LyQXlfIUXpkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trying out Knowledge Graph Memory"
      ],
      "metadata": {
        "id": "JgLcE5JNXJ4y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# workaround again\n",
        "class AnswerKnowledgeGraphMemory(ConversationKGMemory):\n",
        "    def save_context(self, inputs: Dict[str, Any], outputs: Dict[str, str]) -> None:\n",
        "        return super(AnswerKnowledgeGraphMemory, self).save_context(inputs,{'response': outputs['result']})"
      ],
      "metadata": {
        "id": "91efKKBfYRX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationKGMemory\n",
        "\n",
        "memory = AnswerKnowledgeGraphMemory(llm=hf_pipeline)\n",
        "\n",
        "qa_chain_with_kg_memory = RetrievalQA.from_chain_type(llm=hf_pipeline,\n",
        "                                                      chain_type=\"stuff\", \n",
        "                                                      retriever=retriever, \n",
        "                                                      return_source_documents=True,                                                      \n",
        "                                                      memory=memory)"
      ],
      "metadata": {
        "id": "wrvp8YElXJAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# try to set the tone to \"as a human-like Student Advisor\"\n",
        "template = '''\n",
        "You are a prospective student advisor for a university. You are talkative and provide lots of specific details using the context given by the users question. \n",
        "If you don't know the answer, you truthfully say you don't know and don't try to make up an answer. You use the information contained in the \"Relevant Information\" section and You always answer with unbiased, ETHICAL and safe advise.\n",
        "\n",
        "Relevant Information:\n",
        "{history}\n",
        "\n",
        "Conversation:\n",
        "\n",
        "Question: {question}\n",
        "Helpful Answer:'''\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"history\", \"question\"], template=template)"
      ],
      "metadata": {
        "id": "bRyB7IKqawgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_chain_with_kg_memory.combine_documents_chain.llm_chain.prompt = prompt\n",
        "qa_chain_with_kg_memory.combine_documents_chain.llm_chain.prompt"
      ],
      "metadata": {
        "id": "_uwQpwNiad9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_chain_with_kg_memory.combine_documents_chain"
      ],
      "metadata": {
        "id": "4P0sTEt_bb3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"I am interested in both medicine and engineering, do you have a program that is a mix of the two?\"\n",
        "llm_response = qa_chain_with_kg_memory(query)\n",
        "process_llm_response(llm_response)"
      ],
      "metadata": {
        "id": "DVGILZroX26Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"I like biomedical engineering, do you offer it as a graduate program?\"\n",
        "llm_response = qa_chain_with_kg_memory(query)\n",
        "process_llm_response(llm_response)"
      ],
      "metadata": {
        "id": "MWRfmWJ9dw-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"How much is tuition for this program?\"\n",
        "llm_response = qa_chain_with_kg_memory(query)\n",
        "process_llm_response(llm_response)"
      ],
      "metadata": {
        "id": "cLV9CqRcekw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"WOw, expensive! is this the fee for international students?\"\n",
        "llm_response = qa_chain_with_kg_memory(query)\n",
        "process_llm_response(llm_response)"
      ],
      "metadata": {
        "id": "nGh787gsexk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Notes for next version\n",
        "- Make a National Building Code chatbot \n",
        "- Make a school board chatbot\n",
        "- See if 7B model can be handled by free DataBricks\n",
        "- Figure out how to handle data in databricks using dbfs ([Dolly Example](https://www.dbdemos.ai/demo-notebooks.html?demoName=llm-dolly-chatbot))"
      ],
      "metadata": {
        "id": "Q3q2ApRuEmIW"
      }
    }
  ]
}